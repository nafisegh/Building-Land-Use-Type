{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c654a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from tensorflow import keras \n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f995a4",
   "metadata": {},
   "source": [
    "# Split Train Images to Train and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b06043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, shutil, os\n",
    "\n",
    "class_folder=['apartment','church','house','industrial','mixed_rc','officebuilding','retail']\n",
    "\n",
    "for i in range(NUM_FOLD):\n",
    "    \n",
    "    for c in class_folder:\n",
    "        \n",
    "        os.makedirs(f'D:/Nafiseh/building_type/cross_validation_subset_2000/dataset_folds_{i}/images/train/'+c,exist_ok= True)\n",
    "\n",
    "        file_paths = glob.glob(f'D:/Nafiseh/building_type/cross_validation/dataset_folds_{i}/images/train/'+c+'/*.jpg')\n",
    "        \n",
    "        for ff in file_paths:\n",
    "        \n",
    "            shutil.copyfile(ff,f'D:/Nafiseh/building_type/cross_validation_subset_2000/dataset_folds_{i}/images/train/'+c+f'/{os.path.basename(ff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a65f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folder=['apartment','church','house','industrial','mixed_rc','officebuilding','retail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51471092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(IMG_SHAPE):\n",
    "\n",
    "    #preprocess_input=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "    #base_model=tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE+(3,),include_top=False,weights='imagenet')\n",
    "    \n",
    "    preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "    \n",
    "    base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE+(3,), include_top=False, weights='imagenet')\n",
    "\n",
    "    base_model.trainable=True\n",
    "    \n",
    "    #fine_tune_at = 104\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        \n",
    "        layer.trainable = True\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "    feature_batch_average = global_average_layer(base_model.output)\n",
    "\n",
    "    num_classes=7\n",
    "    \n",
    "    #base_learning_rate=0.0001\n",
    "\n",
    "    initializer=tf.keras.initializers.VarianceScaling(scale = 1, mode ='fan_avg', distribution = 'truncated_normal')\n",
    "\n",
    "    prediction_layer=tf.keras.layers.Dense(num_classes,kernel_initializer=initializer, activation = 'softmax')\n",
    "\n",
    "    prediction_batch=prediction_layer(feature_batch_average)\n",
    "\n",
    "    inputs=tf.keras.Input(shape= IMG_SHAPE+(3,))\n",
    "\n",
    "    #x=data_augmentation(inputs)\n",
    "\n",
    "    x=preprocess_input(inputs)\n",
    "\n",
    "    #x=base_model(x,training=False)\n",
    "\n",
    "    x=base_model(x)\n",
    "\n",
    "    x=global_average_layer(x)\n",
    "\n",
    "    x=tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs=prediction_layer(x)\n",
    "\n",
    "    model=tf.keras.Model(inputs,outputs)\n",
    "\n",
    "    #model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  #optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "                  #metrics=['accuracy'])\n",
    "            \n",
    "    #decay_steps = 500\n",
    "    decay_steps = 234 #int(num training samples/batch size)\n",
    "    decay_rate = 0.98 #(initial_lr/final_lr)**(1/epochs)\n",
    "    lr_scheduler = ExponentialDecay(0.001, decay_steps, decay_rate)  \n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                 optimizer = tf.keras.optimizers.SGD(learning_rate=lr_scheduler),metrics=['accuracy'])\n",
    "    \n",
    "    return (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5293515",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kfold = pd.DataFrame()\n",
    "true_class = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 300\n",
    "SEED = 1\n",
    "NUM_FOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c349acc",
   "metadata": {},
   "source": [
    "# Class for measuring training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a39cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cd455",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Initializing Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale = 1,\n",
    "                                   shear_range = 0,\n",
    "                                   zoom_range = 1,\n",
    "                                   horizontal_flip = False)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta = 10**-2, patience =100, restore_best_weights =True)\n",
    "\n",
    "\n",
    "for j in range(NUM_FOLD): \n",
    "    \n",
    "    #x_train_df = dff.iloc[train_idx]\n",
    "    \n",
    "    #x_valid_df = dff.iloc[val_idx]\n",
    "    \n",
    "    #j+=1\n",
    "\n",
    "\n",
    "    #training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n",
    "                                                 #x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 #class_mode=\"categorical\",\n",
    "                                                 #target_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "                                                 \n",
    "    training_set = train_datagen.flow_from_directory(directory = \n",
    "                                                     f'D:/Nafiseh/building_type/cross_validation/dataset_folds_{j}/images/train/', target_size = IMG_SIZE, \n",
    "    \n",
    "                                                          color_mode = 'rgb',  batch_size = BATCH_SIZE, \n",
    "                                                          class_mode = 'categorical', shuffle =True, seed = 10)                                              \n",
    "    \n",
    "    #validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n",
    "                                                 #x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 #class_mode=\"categorical\",\n",
    "                                                 #target_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "                                                 \n",
    "    validation_set = validation_datagen.flow_from_directory(directory = \n",
    "                                                            f'D:/Nafiseh/building_type/cross_validation/dataset_folds_{j}/images/valid/', target_size = IMG_SIZE,\n",
    "                                                            \n",
    "                                                            color_mode = 'rgb', batch_size = BATCH_SIZE,\n",
    "                                                            class_mode = 'categorical', shuffle = True, seed = 10)                                               \n",
    "    \n",
    "    model_test = get_model(IMG_SIZE)\n",
    "    \n",
    "    cb = TimingCallback()\n",
    "    \n",
    "    \n",
    "    \n",
    "    history = model_test.fit( training_set,\n",
    "                                        validation_data=validation_set,\n",
    "                                        epochs = EPOCHS,\n",
    "                                        steps_per_epoch= training_set.samples // BATCH_SIZE, callbacks = [es,cb]\n",
    "                                        )\n",
    "    \n",
    "    print(cb.logs)\n",
    "    \n",
    "    print(f'Training Time for fold {j} is ',sum(cb.logs))\n",
    "                                        \n",
    "                                        \n",
    "    model_test.save(f'D:/Nafiseh/building_type/model_vgg16_training_from_scratch_fold_{j}_SGD_2000_train.h5')\n",
    "    \n",
    "    with open(f'D:/Nafiseh/building_type/model_vgg16_history_training_from_scratch_fold_{j}_SGD_2000_train','wb') as model_history:\n",
    "    \n",
    "      pickle.dump(history.history, model_history)\n",
    "    \n",
    "    \n",
    "    #test_set = test_generator.flow_from_dataframe(dataframe=train, directory=TRAIN_PATH,\n",
    "                                                 #x_col=\"Image\",y_col=\"Class\",\n",
    "                                                 #class_mode=None,\n",
    "                                                 #target_size=IMG_SIZE)\n",
    "                                                 \n",
    "    test_set = test_generator.flow_from_directory(directory = f'D:/Nafiseh/building_type/cross_validation/dataset_folds_{j}/images/test/', target_size = IMG_SIZE,\n",
    "    \n",
    "                                                color_mode = 'rgb', batch_size = BATCH_SIZE,\n",
    "                                                class_mode = 'categorical', shuffle= False) \n",
    "                                                \n",
    "                                                \n",
    "    true_class[j] = pd.Series(test_set.labels)\n",
    "                                                \n",
    "    \n",
    "    pred= model_test.predict(test_set, test_set.samples // BATCH_SIZE)\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "                                       \n",
    "    data_kfold[j] = pd.Series(predicted_class_indices)\n",
    "    \n",
    "    np.save(f'D:/Nafiseh/building_type/data_fold_{j}_training_from_scratch_vgg16_SGD_2000_train.npy',data_kfold[j])\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f675387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FOLD = 5\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "true_class = pd.DataFrame()\n",
    "data_kfold_2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "for f in range(NUM_FOLD):\n",
    "    \n",
    "    model_test = load_model(f'D:/Nafiseh/building_type/model_vgg16_training_10_layers_fold_{f}_SGD_train_2000.h5',compile=False)\n",
    "\n",
    "    \n",
    "                                                    \n",
    "    #test_set = test_generator.flow_from_directory(directory = f'D:/Nafiseh/building_type/cross_validation/dataset_folds_{f}/images/test/', target_size = IMG_SIZE,\n",
    "    \n",
    "                                                #color_mode = 'rgb', batch_size = BATCH_SIZE,\n",
    "                                                #class_mode = 'categorical',shuffle = False) \n",
    "            \n",
    "            \n",
    "    \n",
    "    test_set = test_generator.flow_from_directory(directory = f'D:/Nafiseh/building_type/Toronto/My_classes_web_and_google_dataset_2/', target_size = IMG_SIZE,\n",
    "                                                 \n",
    "                                                 color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'categorical', shuffle = False)\n",
    "\n",
    "    true_class[f] = pd.Series(test_set.labels)\n",
    "                                                \n",
    "    \n",
    "    pred= model_test.predict(test_set, test_set.samples // BATCH_SIZE)\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "                                       \n",
    "    data_kfold_2[f] = pd.Series(predicted_class_indices)\n",
    "    \n",
    "    #np.save(f'D:/Nafiseh/building_type/model_vgg16_data_fold_{f}_training_0_layers_SGD_2000_train.npy',data_kfold[f])\n",
    "    \n",
    "    #np.save(f'D:/Nafiseh/building_type/model_mobilenetv2_training_150_layers_data_fold_{f}_Toronto_dataset_2_label_corrected.npy',data_kfold[f])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import os\n",
    "\n",
    "mobilenetv2 = read_csv('D:/Nafiseh/building_type/Toronto/dataset_2_MobilenetV2_fine_tune_150_layers_predictions.csv')\n",
    "\n",
    "vgg16 = read_csv('D:/Nafiseh/building_type/Toronto/dataset_2_vgg16_training_10_layers_predictions.csv')\n",
    "\n",
    "E=[]\n",
    "\n",
    "for _,i in vgg16.iterrows():\n",
    "\n",
    "    if i['class_ref_2'] != i['class_ref']:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            shutil.move('D:\\\\Nafiseh\\\\building_type\\\\Toronto\\\\My_Classes_web_and_google_dataset_2\\\\'+i['Image'],'D:\\\\Nafiseh\\\\building_type\\\\Toronto\\\\My_Classes_web_and_google_dataset_2\\\\'+i['class_ref_2']+'\\\\'+i['Image'].split('\\\\',1)[1])\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans = train.copy()\n",
    "ans_2 = pd.DataFrame(index = np.arange(len(data_kfold)), columns=['Class'])\n",
    "\n",
    "\n",
    "\n",
    "# Taking The Label with Maximum Occurences\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1,\n",
    "                                   shear_range = 0,\n",
    "                                   zoom_range = 1,\n",
    "                                   horizontal_flip = False)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(directory = \n",
    "                                                 'D:/Nafiseh/building_type/cross_validation/dataset_folds_0/images/train/', target_size = IMG_SIZE, \n",
    "\n",
    "                                                      color_mode = 'rgb',  batch_size = BATCH_SIZE, \n",
    "                                                      class_mode = 'categorical', shuffle =True, seed = 10)   \n",
    "\n",
    "\n",
    "labels=(training_set.class_indices)\n",
    "\n",
    "labels2=dict((v,k) for k,v in labels.items())\n",
    "import collections \n",
    "for i in range(len(data_kfold_2)):\n",
    "    co = collections.Counter(data_kfold_2.loc[i])\n",
    "    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n",
    "    ans_2.Class.loc[i] = co[0][0]\n",
    "\n",
    "\n",
    "#ans_array = np.array(ans.Class, dtype=int)\n",
    "\n",
    "#true_class.iloc[:,0] = true_class.iloc[:,0].replace(5,6)\n",
    "\n",
    "#true_class.iloc[:,0] = true_class.iloc[:,0].replace(4,5)\n",
    "\n",
    "#true_class.iloc[:,0] = true_class.iloc[:,0].replace(3,4)\n",
    "\n",
    "#true_class.iloc[:,0] = true_class.iloc[:,0].replace(2,3)\n",
    "\n",
    "#true_class.iloc[:,0] = true_class.iloc[:,0].replace(1,2)\n",
    "\n",
    "\n",
    "# Averaged K-Fold Output\n",
    "print(\"Accuracy of K-Fold Method: \",accuracy_score(list(true_class.iloc[:2970,0]), list(ans_2.Class.iloc[:2970])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e5214",
   "metadata": {},
   "source": [
    "# Count Number of Class Occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a569d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 7\n",
    "\n",
    "score_2 = np.zeros((data_kfold.shape[0],num_class))\n",
    "\n",
    "for i in range(data_kfold.shape[0]):\n",
    "    \n",
    "    for c in range(num_class):\n",
    "\n",
    "        score_2[i,c] = np.count_nonzero(np.array(data_kfold)[i,:] == c)/NUM_FOLD\n",
    "\n",
    "print(score_2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b5d3d",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(list(ans.Class))\n",
    "\n",
    "label_onehot = label_binarizer.transform(list(ans.Class))\n",
    "\n",
    "label_binarizer_2 = LabelBinarizer().fit(list(ans_2.Class))\n",
    "\n",
    "label_onehot_2 = label_binarizer_2.transform(list(ans_2.Class))\n",
    "\n",
    "label_onehott = [label_onehot, label_onehot_2]\n",
    "\n",
    "colors = [\"darkblue\",\"darkorange\"]\n",
    "\n",
    "models = ['MobilenetV2','VGG16']\n",
    "\n",
    "scoree =[score, score_2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,15))\n",
    "\n",
    "\n",
    "for l,s,c,m in zip(label_onehott, scoree, colors, models):\n",
    "\n",
    "    RocCurveDisplay.from_predictions(l.ravel(), s.ravel(), linewidth= 5, name = \"{} micro-average OvR\".format(m), color = c, ax= ax)\n",
    "\n",
    "plt.plot([0,1],[0,1],\"k--\", linewidth = 5, label = \"chance level (AUC = 0.5)\")\n",
    "\n",
    "plt.axis('square')\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.xlabel('False Positive Rate',fontsize= 15)\n",
    "\n",
    "plt.ylabel('True Positive Rate',fontsize= 15)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df.loc[:,'Image'] = test_set.filenames\n",
    "\n",
    "for  i in range(NUM_FOLD):\n",
    "\n",
    "    df.loc[:,f'fold{i+1}'] = data_kfold[i] \n",
    "    \n",
    "    \n",
    "    \n",
    "display(df) \n",
    "\n",
    "df.to_csv('D:/Nafiseh/building_type/Toronto/mobilenetv2_prediction_datasset_2_label_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(list(true_class.iloc[:2790,0]))  #train here refers to the data used as test!!\n",
    "\n",
    "train_categorical = le.transform(list(true_class.iloc[:2790,0]))\n",
    "\n",
    "pred_categorical = le.transform(ans.Class.iloc[:2790])\n",
    "    \n",
    "confusion_matrix=tf.math.confusion_matrix(labels= train_categorical, predictions= pred_categorical).numpy()  \n",
    "\n",
    "_,ax=plt.subplots(figsize=(25,15))\n",
    "\n",
    "sns.set (font_scale = 3)\n",
    "\n",
    "sns.heatmap(confusion_matrix/np.sum(confusion_matrix,axis=1)[:,None], annot=True, fmt='.2%', cmap='Blues',ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted labels',fontweight='bold',fontsize = 20)\n",
    "ax.set_ylabel('True labels',fontweight='bold',fontsize = 20)\n",
    "ax.set_title('Confusion Matrix',fontweight='bold',fontsize = 26) \n",
    "\n",
    "\n",
    "ax.xaxis.set_ticklabels(['apartment', 'church','house','industrial','mixed \\n residential \\n commercial',\n",
    "                        'officebuilding','retail'], fontsize = 18)\n",
    "\n",
    "ax.yaxis.set_ticklabels(['apartment', 'church','house','industrial','mixed \\n residential \\n commercial',\n",
    "                        'officebuilding','retail'], fontsize = 18)\n",
    "\n",
    "#plt.savefig('D:/Nafiseh/building_type/confusion_matrix_mobilenetv2_label_corrected.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d73e9",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7de19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint,seed\n",
    "import glob, os\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "\n",
    "#history_names = ['model_vgg16_history_training_0_layers', 'model_vgg16_history_training_5_layers',\n",
    "                #'model_vgg16_history_training_l0_layers','model_vgg16_history_training_from_scratch']\n",
    "    \n",
    "#history_names = ['0.001','0.0001','0.00001','10-6']   \n",
    "\n",
    "history_names = ['10-3']\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#num_fine_tune_layers = ['Transfer Learning','5', '10', 'From Scratch']\n",
    "\n",
    "#num_fine_tune_layers = ['Learning Rate = 10-3','Learning Rate = 10-4','Learning Rate = 10-5','Learning Rate = 10-6']\n",
    "\n",
    "num_fine_tune_layers = ['fine_tune_300_layers','fine_tune_250_layers','fine_tune_200_layers',\n",
    "                       'fine_tune_150_layers','fine_tune_100_layers','fine_tune_50_layers']\n",
    "\n",
    "num_layers = ['Fine Tune 300 Layers','Fine Tune 250 Layers','Fine Tune 200 Layers','Fine Tune 150 Layers',\n",
    "             'Fine Tune 100 Layers','Fine Tune 50 Layers']\n",
    "\n",
    "seed(4)\n",
    "\n",
    "colors = ['#%06X' % randint(0,0xFFFFFF) for i in range(50)]\n",
    "\n",
    "matplotlib.style.use('seaborn-v0_8')\n",
    "\n",
    "fig,ax = plt.subplots(2,1, figsize= (360,280))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "#matplotlib.rc('xtick', labelsize=80) \n",
    "#matplotlib.rc('ytick', labelsize=80) \n",
    "\n",
    "\n",
    "for h,file in zip(range(len(history_names)),history_names):\n",
    "    \n",
    "    for n in num_fine_tune_layers:\n",
    "    \n",
    "        for f in range(NUM_FOLDS):\n",
    "\n",
    "            counter+=1\n",
    "\n",
    "            #with open('D:/Nafiseh/building_type/LiDAR/model_histories/'+file+f'_fold_{f}_SGD_train_2000','rb') as pickle_file:\n",
    "            if n == 'full_features_training_from_scratch':\n",
    "\n",
    "                with open(f'D:/Nafiseh/building_type/LiDAR/model_histories/shuffled_inception_v3_model_history_lidar_balanced_200_{n}_fold_{f+1}_SGD_initial_lr_{file}','rb') as pickle_file:\n",
    "\n",
    "                   history = pickle.load(pickle_file)\n",
    "            else:\n",
    "                \n",
    "                with open(f'D:/Nafiseh/building_type/LiDAR/model_histories/shuffled_inception_v3_model_history_lidar_balanced_200_{n}_fold_{f+1}_adam_initial_lr_{file}_dropout_0.8_batch_size_15','rb') as pickle_file:\n",
    "                \n",
    "                   history = pickle.load(pickle_file)\n",
    "                    \n",
    "            line1, = ax[0].plot(history['loss'], c= colors[counter], linewidth = 20, label = f'Train loss fold {f+1} ({num_layers[h]})' )\n",
    "\n",
    "            line2, = ax[0].plot(history['val_loss'], c= colors[counter], linewidth = 20, label = f'Validation loss fold {f+1} ({num_layers[h]})')\n",
    "\n",
    "\n",
    "            ax[0].legend(loc = 'upper center',bbox_to_anchor = (0.5, -0.1),ncol = 5, fontsize = 200)\n",
    "\n",
    "            line3, = ax[1].plot(history['accuracy'], c= colors[counter], linewidth = 20, label = f'Train Acuuracy fold {f+1} ({num_layers[h]})')\n",
    "\n",
    "            line4, = ax[1].plot(history['val_accuracy'], c= colors[counter], linewidth = 20, label = f'Validation Accuracy fold {f+1} ({num_layers[h]})')\n",
    "\n",
    "            ax[1].legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.1), ncol = 5, fontsize = 200)\n",
    "\n",
    " \n",
    "ax[0].set_xlabel('Epochs',weight = 'bold', fontsize = 200)\n",
    "        \n",
    "ax[0].set_ylabel('Categorical Cross Entropy', weight = 'bold', fontsize = 200)\n",
    "\n",
    "ax[0].tick_params(labelsize = 130)\n",
    "\n",
    "ax[0].grid()       \n",
    "        \n",
    "        \n",
    "ax[1].set_xlabel('Epochs', weight = 'bold', fontsize = 200)\n",
    "        \n",
    "ax[1].set_ylabel('Accuracy', weight = 'bold', fontsize = 200) \n",
    "\n",
    "ax[1].tick_params(labelsize = 130)\n",
    "\n",
    "ax[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('D:/Nafiseh/building_type/Building_Type_Manuscript/Figures/Learning curves InceptionV3 LiDAR_4.tif') \n",
    "\n",
    "        \n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dce9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jakteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install laspy[laszip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install otb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7aac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jakteristics import las_utils, compute_features, FEATURE_NAMES\n",
    "\n",
    "import laspy, glob, os\n",
    "\n",
    "\n",
    "#las_files = glob.glob('G:/Backedup_ssc_2430_10/MyProject2/Ontario_2015_point_cloud_2/Ontario_2015_point_cloud_2_las/*.las')\n",
    "\n",
    "\n",
    "las_files = ['G:/Backedup_ssc_2430_10/MyProject2/Ontario_2015_point_cloud_2/Ontario_2015_point_cloud_2_las/1km176290483502015LGTA2015_CPC.las',\n",
    "             'G:/Backedup_ssc_2430_10/MyProject2/Ontario_2015_point_cloud_2/Ontario_2015_point_cloud_2_las/1km176310483502015LGTA2015_CPC.las']\n",
    "\n",
    "features = ['eigenvalue_sum', 'omnivariance', 'eigenentropy', 'anisotropy', 'planarity', 'linearity', 'PCA1', 'PCA2', 'surface_variation', 'sphericity', 'verticality']\n",
    "\n",
    "for f in las_files:\n",
    "    \n",
    "    for idx, ff in enumerate(features):\n",
    "\n",
    "        xyz = las_utils.read_las_xyz(f)\n",
    "\n",
    "        #building_points = las.points[las.classification == 6] #6:buildings\n",
    "\n",
    "        features_point_cloud = compute_features(xyz, search_radius=0.15, feature_names=[ff])\n",
    "\n",
    "        tmp = os.path.basename(f).split('.las')[0]\n",
    "        \n",
    "        output_las_file = f'D:/Nafiseh/Building_Footprint_Clip/point_cloud_covariance_features_2/{tmp}_{ff}.las'\n",
    "\n",
    "        las_utils.write_with_extra_dims(f, output_las_file, features_point_cloud, [ff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9991de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_point_cloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import otbApplication\n",
    "\n",
    "HaralickTextureExtraction = otbApplication.Registrry.CreateApplication('HaralickTextureExtraction')\n",
    "\n",
    "HaralickTextureExtraction.SetParameterString('in','D:/Nafiseh/Building_Footprint_Clip/DSM_2.tif')\n",
    "\n",
    "HaralickTextureExtraction.SetParameterInt('channels',1)\n",
    "\n",
    "HaralickTextureExtraction.SetParameterInt('parameters.xrad',3)\n",
    "\n",
    "HaralickTextureExtraction.SetParameterInt('parameters.yrad',3)\n",
    "\n",
    "HaralickTextureExtraction.SetParameterString('texture','simple')\n",
    "\n",
    "HaralickTextureExtraction.SetParameterString('out','D:/Nafiseh/building_type/LiDAR/GLCM_Features.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d648759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(dic,val):\n",
    "    \n",
    "    for key,value in dic.items():\n",
    "        \n",
    "        if val == value:\n",
    "            \n",
    "           return(key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54735c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install basemap\n",
    "#!pip install basemap-data-hires\n",
    "#!pip install contextily\n",
    "import shapefile as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas as gp\n",
    "import contextily as cx\n",
    "\n",
    "\n",
    "\n",
    "sf = shp.Reader('D:/Nafiseh/building_type/Toronto_joined_building_fp_2_wgs84.shp')\n",
    "\n",
    "sf_gta_boundary = shp.Reader('D:/Nafiseh/building_type/Part_of_GTA_Boundary.shp')\n",
    "\n",
    "#fields = [f[0] for f in sf.fields[1:]]\n",
    "\n",
    "#pr = np.array([x['prediction'] for x in sf.iterRecords()])\n",
    "\n",
    "ref = np.array([x['referenc_1'] for x in sf.iterRecords()])\n",
    "\n",
    "lat = np.array([x['Latitude'] for x in sf.iterRecords()])\n",
    "\n",
    "long = np.array([x['Longitude'] for x in sf.iterRecords()])\n",
    "\n",
    "ref[ref == '#N/A']='apartment'\n",
    "\n",
    "#pr = pr.astype(int)\n",
    "\n",
    "colors = ['blue','green','orange','red','darkred','magenta']\n",
    "\n",
    "ref_color = dict(zip(colors,np.unique(ref)))\n",
    "\n",
    "ref_ = list(ref_color.values())\n",
    "\n",
    "c_ = list(ref_color.keys())\n",
    "\n",
    "#print(pr)\n",
    "\n",
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "fig.set_dpi(300)\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "labels=[]\n",
    "for r,shape in zip(ref,sf.shapeRecords()):\n",
    "\n",
    "         x = [i[0] for i in shape.shape.points[:]]\n",
    "\n",
    "         y = [i[1] for i in shape.shape.points[:]]\n",
    " \n",
    "         if r in labels:   \n",
    "\n",
    "             plt.plot(x,y,c=get_key(ref_color,r), linewidth=100, alpha=0.7)\n",
    "                \n",
    "         else:\n",
    "            \n",
    "             plt.plot(x,y,c=get_key(ref_color,r),linewidth=100,label=r,alpha=0.7)\n",
    "                \n",
    "         labels.append(r)        \n",
    "                \n",
    "    \n",
    "for shape in sf_gta_boundary.shapeRecords():\n",
    "\n",
    "     x1 = [i[0] for i in shape.shape.points[:]]\n",
    "        \n",
    "     y1 = [i[1] for i in shape.shape.points[:]] \n",
    "    \n",
    "     plt.plot(x1,y1, linewidth=25, c='black', label='Part of GTA Boundary',alpha=0.7) \n",
    "        \n",
    "         \n",
    "ax = plt.gca()\n",
    "\n",
    "cx.add_basemap(ax, crs=4326)\n",
    "\n",
    "plt.xticks(fontsize=150)\n",
    "\n",
    "plt.yticks(fontsize=150)\n",
    "\n",
    "plt.legend(prop={'size':100})\n",
    "\n",
    "plt.savefig('D:/Nafiseh/building_type/Building_Type_Manuscript/Figures/Toronto_Map_2.tif',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install basemap\n",
    "#!pip install basemap-data-hires\n",
    "#!pip install contextily\n",
    "import shapefile as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas as gp\n",
    "import contextily as cx\n",
    "\n",
    "\n",
    "\n",
    "sf = shp.Reader('D:/Nafiseh/building_type/Toronto_joined_building_fp_2_wgs84.shp')\n",
    "\n",
    "sf_gta_boundary = shp.Reader('D:/Nafiseh/building_type/Part_of_GTA_Boundary.shp')\n",
    "\n",
    "#fields = [f[0] for f in sf.fields[1:]]\n",
    "\n",
    "pr = np.array([x['prediction'] for x in sf.iterRecords()])\n",
    "\n",
    "ref = np.array([x['referenc_1'] for x in sf.iterRecords()])\n",
    "\n",
    "lat = np.array([x['Latitude'] for x in sf.iterRecords()])\n",
    "\n",
    "long = np.array([x['Longitude'] for x in sf.iterRecords()])\n",
    "\n",
    "ref[ref == '#N/A']='apartment'\n",
    "\n",
    "pr[pr == '#N/A']='0'\n",
    "\n",
    "#pr = pr.astype(int)\n",
    "\n",
    "colors = ['blue','green','orange','red','darkred','magenta']\n",
    "\n",
    "colors_2 = ['blue','cyan','green','orange','red','darkred','magenta']\n",
    "\n",
    "ref_color = dict(zip(colors,np.unique(ref)))\n",
    "\n",
    "p_color = dict(zip(colors_2, np.unique(pr)))\n",
    "\n",
    "p_num_desc = dict(zip(np.unique(pr),np.array(['apartment','church','house','industrial','mixed r/c','office building','retail'])))\n",
    "\n",
    "ref_ = list(ref_color.values())\n",
    "\n",
    "c_ = list(ref_color.keys())\n",
    "\n",
    "#print(pr)\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(200,100))\n",
    "\n",
    "fig.set_dpi(300)\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "\n",
    "\n",
    "labels=[]\n",
    "for r,shape in zip(ref,sf.shapeRecords()):\n",
    "\n",
    "         x = [i[0] for i in shape.shape.points[:]]\n",
    "\n",
    "         y = [i[1] for i in shape.shape.points[:]]\n",
    " \n",
    "         if r in labels:   \n",
    "\n",
    "             ax[0].plot(x,y,c=get_key(ref_color,r), linewidth=100, alpha=0.7)\n",
    "                \n",
    "         else:\n",
    "            \n",
    "             ax[0].plot(x,y,c=get_key(ref_color,r),linewidth=100,label=r,alpha=0.7)\n",
    "                \n",
    "         labels.append(r)        \n",
    "                \n",
    "    \n",
    "for shape in sf_gta_boundary.shapeRecords():\n",
    "\n",
    "     x1 = [i[0] for i in shape.shape.points[:]]\n",
    "        \n",
    "     y1 = [i[1] for i in shape.shape.points[:]] \n",
    "    \n",
    "     ax[0].plot(x1,y1, linewidth=25, c='black', label='Part of GTA Boundary',alpha=0.7) \n",
    "\n",
    "cx.add_basemap(ax[0], crs=4326)\n",
    "\n",
    "#ax[0].set_title('Ground Truth Map',fontsize=200)\n",
    "\n",
    "ax[0].set_xlabel('(a)', fontsize =150, weight='bold')\n",
    "\n",
    "ax[0].tick_params(axis='x', labelsize=150)\n",
    "\n",
    "ax[0].tick_params(axis='y', labelsize=150)\n",
    "\n",
    "ax[0].legend(prop={'size':100})\n",
    "\n",
    "labels_2=[]\n",
    "\n",
    "for p,shape in zip(pr,sf.shapeRecords()):\n",
    "    \n",
    "    x2 = [i[0] for i in shape.shape.points[:]]\n",
    "    \n",
    "    y2 = [i[1] for i in shape.shape.points[:]]\n",
    "    \n",
    "    if p in labels_2:\n",
    "    \n",
    "        ax[1].plot(x2,y2, c=get_key(p_color,p),linewidth=100,alpha=0.7)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ax[1].plot(x2,y2,c=get_key(p_color,p),linewidth=100,label=p_num_desc[p],alpha=0.7)\n",
    "        \n",
    "    labels_2.append(p)\n",
    "    \n",
    "for shape in sf_gta_boundary.shapeRecords():\n",
    "    \n",
    "     x3 = [i[0] for i in shape.shape.points[:]]\n",
    "        \n",
    "     y3 = [i[1] for i in shape.shape.points[:]]\n",
    "    \n",
    "     ax[1].plot(x3,y3,linewidth=25,c='black',label='Part of GTA Boundary',alpha=0.7)    \n",
    "    \n",
    "cx.add_basemap(ax[1], crs=4326) \n",
    "\n",
    "#ax[1].set_title('Predicted Map',fontsize=200)\n",
    "\n",
    "\n",
    "ax[1].set_xlabel('(b)', fontsize =150, weight='bold')\n",
    "\n",
    "ax[1].tick_params(axis='x', labelsize=150)\n",
    "\n",
    "ax[1].tick_params(axis='y', labelsize=150)\n",
    "\n",
    "ax[1].legend(prop={'size':100})\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig('D:/Nafiseh/building_type/Building_Type_Manuscript/Figures/Toronto_Map_4.tif',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911675ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.array([x['prediction'] for x in sf.iterRecords()])\n",
    "\n",
    "pr[pr == '#N/A']='0'\n",
    "\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num_desc = dict(zip(np.unique(pr),np.array(['apartment','church','house','industrial','mixed r/c','office building','retail'])))\n",
    "\n",
    "\n",
    "print(p_num_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae889c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
