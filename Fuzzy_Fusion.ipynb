{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Deep Learning Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vancouver Probability Arrays have shapes: \n",
      " (184, 60) (184, 35)\n",
      "Fortworth Probability Arrays have shapes: \n",
      " (401, 60) (401, 35)\n"
     ]
    }
   ],
   "source": [
    "# Orthophoto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#fortworth_prob_ortho = np.load('D:/Nafiseh/building_type/Orthophoto/Results/probability_fortworth_orthophoto.npy')\n",
    "\n",
    "#df = pd.read_csv('D:/Nafiseh/building_type/vancouver_prob_test.csv', usecols = lambda x: x not in ['OID_', 'Object_ID_1','Geom','obj_id_lng','object_id_12'])\n",
    "df = pd.read_csv('D:/Nafiseh/building_type/vancouver_prob_test_2.csv')\n",
    "\n",
    "df_fortworth = pd.read_csv('D:/Nafiseh/building_type/fortworth_prob_test_2.csv')\n",
    "#print(fortworth_prob_ortho.shape)\n",
    "\n",
    "\n",
    "def create_column_names(mode):\n",
    "    \n",
    "    dtype1 = ['ortho','lidar']\n",
    "    \n",
    "    dtype2 = ['gsv']\n",
    "    \n",
    "    NUM_FOLDS = 5\n",
    "\n",
    "    classes1 = ['industrial','institutional','office_building','other','residential','retail']\n",
    "    \n",
    "    classes2 = ['apartment','church','house','industrial','mixed_r_c','office_building','retail']\n",
    "\n",
    "    prob_columns = []\n",
    "    \n",
    "    if mode == 1:\n",
    "\n",
    "        for d in dtype1:\n",
    "\n",
    "            for f in range(1,NUM_FOLDS+1):\n",
    "\n",
    "                for c in classes1:\n",
    "\n",
    "                    prob_columns.append(f'Prob_{c}_{d}_fold_{f}')\n",
    "\n",
    "    elif mode == 2:\n",
    "        \n",
    "        \n",
    "        for d in dtype2:\n",
    "\n",
    "            for f in range(1,NUM_FOLDS+1):\n",
    "\n",
    "                for c in classes2:\n",
    "\n",
    "                    prob_columns.append(f'Prob_{c}_{d}_fold_{f}')\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "       raise Exception('mode should be either 1 or 2') \n",
    "        \n",
    "    return(prob_columns) \n",
    "\n",
    "############\n",
    "\n",
    "vancouver_prob_array_ortho_lidar = np.array(df[create_column_names(1)])\n",
    "\n",
    "vancouver_prob_array_gsv = np.array(df[create_column_names(2)])\n",
    "\n",
    "##############\n",
    "\n",
    "fortworth_prob_array_ortho_lidar = np.array(df_fortworth[create_column_names(1)])\n",
    "\n",
    "fortworth_prob_array_gsv = np.array(df_fortworth[create_column_names(2)])\n",
    "\n",
    "###############\n",
    "\n",
    "print('Vancouver Probability Arrays have shapes: \\n', vancouver_prob_array_ortho_lidar.shape, vancouver_prob_array_gsv.shape)\n",
    "\n",
    "print('Fortworth Probability Arrays have shapes: \\n', fortworth_prob_array_ortho_lidar.shape, fortworth_prob_array_gsv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Method: Fuzzy-ranking Based Ensemble Using Gombertz Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_rank(CF, top):\n",
    "    R_L = np.zeros(CF.shape)\n",
    "    for i in range(CF.shape[0]):\n",
    "        for j in range(CF.shape[1]):\n",
    "            for k in range(CF.shape[2]):\n",
    "                R_L[i][j][k] = 1 - math.exp(-math.exp(-2.0*CF[i][j][k]))  #Gompertz Function\n",
    "    \n",
    "    K_L = 0.632*np.ones(shape = R_L.shape) #initiate all values as penalty values\n",
    "    for i in range(R_L.shape[0]):\n",
    "        for sample in range(R_L.shape[1]):\n",
    "            for k in range(top):\n",
    "                a = R_L[i][sample]\n",
    "                idx = np.where(a==np.partition(a, k)[k])\n",
    "                #if sample belongs to top 'k' classes, R_L =R_L, else R_L = penalty value\n",
    "                K_L[i][sample][idx] = R_L[i][sample][idx]\n",
    "\n",
    "    return K_L\n",
    "\n",
    "def CFS_func(CF, K_L):\n",
    "    H = CF.shape[0] #no. of classifiers\n",
    "    for f in range(CF.shape[0]):\n",
    "        for i in range(CF.shape[1]):\n",
    "            idx = np.where(K_L[f][i] == 0.632)\n",
    "            CF[f][i][idx] = 0\n",
    "    CFS = 1 - np.sum(CF,axis=0)/H\n",
    "    return CFS\n",
    "\n",
    "def Gompertz(CF ,top = 2):\n",
    "\n",
    "#def Gompertz(top = 2, *argv):\n",
    "    #L = 0 #Number of classifiers\n",
    "\n",
    "    #for arg in argv:\n",
    "        #L += 1\n",
    "\n",
    "    #num_classes = arg.shape[1]\n",
    "    #CF = np.zeros(shape = (L,arg.shape[0], arg.shape[1]))\n",
    "\n",
    "    #for i, arg in enumerate(argv):\n",
    "        #CF[:][:][i] = arg\n",
    "\n",
    "    R_L = fuzzy_rank(CF, top) #R_L is with penalties\n",
    "    \n",
    "    RS = np.sum(R_L, axis=0)\n",
    "\n",
    "    CFS = CFS_func(CF, R_L)\n",
    "\n",
    "    FS = np.multiply(RS,CFS)\n",
    "\n",
    "    predictions = np.argmin(FS,axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Fusion of Orthophoto and LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 2 2 5 5 1 0 4 1 0 0 0 4 2 1 3 4 4 1 0 0 3 4 5 0 0 4 2 3 4 2 5 5 5 0 0\n",
      " 0 4 0 2 4 2 5 3 4 4 5 1 3 2 1 0 3 0 4 4 4 3 4 4 0 3 0 4 4 4 4 1 1 0 0 2 2\n",
      " 2 4 3 2 4 4 5 4 1 4 5 0 4 4 0 4 4 0 1 5 4 4 0 4 3 4 1 1 1 2 2 4 4 4 4 4 5\n",
      " 2 0 4 0 0 0 0 4 4 2 5 3 2 4 4 4 4 5 4 2 2 2 4 4 4 2 4 4 4 5 4 4 4 4 5 4 2\n",
      " 0 0 1 0 3 4 0 3 5 4 3 2 1 4 1 0 3 1 0 5 0 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[5 1 3 3 3 2 3 3 3 3 2 2 3 3 2 3 3 1 5 2 2 3 1 3 1 3 3 3 3 3 2 2 3 2 2 1 2\n",
      " 2 3 2 3 3 3 3 1 2 2 2 1 3 3 3 3 2 2 3 3 3 1 2 2 1 2 3 3 3 3 1 1 1 3 3 1 2\n",
      " 4 2 5 3 5 1 0 5 1 3 3 2 3 3 1 3 2 2 1 1 1 2 3 2 3 3 1 0 3 3 4 3 3 1 1 1 3\n",
      " 3 2 3 2 3 3 1 3 2 3 5 3 3 1 2 2 3 4 4 1 5 5 3 5 2 2 2 2 3 3 4 4 3 3 4 3 3\n",
      " 4 3 3 5 2 3 3 2 5 3 4 3 3 3 3 3 3 4 3 2 4 3 3 4 3 4 2 4 2 4 1 2 3 3 3 5 3\n",
      " 3 2 2 5 3 3 4 3 3 4 4 4 3 4 4 4 3 3 5 5 3 4 4 3 4 4 3 4 3 4 3 3 3 2 4 3 0\n",
      " 3 4 4 1 3 4 4 4 4 3 2 1 5 3 3 3 3 3 3 3 1 3 3 3 3 2 2 3 3 0 4 4 3 3 3 2 3\n",
      " 2 3 3 3 3 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 2 3 3 3 4 4 3 3 2 3 2 3 5 2 4 2 3\n",
      " 2 3 3 3 3 4 3 2 3 2 3 2 2 3 3 5 3 3 3 5 2 3 2 5 3 3 3 4 2 3 3 3 3 4 3 4 1\n",
      " 1 1 5 5 1 5 1 1 2 5 2 3 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 0 0 0 2 0 2 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "CF1 = np.copy(vancouver_prob_array_ortho_lidar)\n",
    "\n",
    "CF1_F = np.copy(fortworth_prob_array_ortho_lidar)\n",
    "\n",
    "def reshape_confidence_matrix (CF):\n",
    "    \n",
    "        \n",
    "    num_classes = 6\n",
    "    \n",
    "    CF_r = np.zeros((int(CF.shape[1]/num_classes), CF.shape[0], num_classes))\n",
    "\n",
    "    indexes = np.arange(0, CF.shape[1],num_classes)\n",
    "    \n",
    "    #print(indexes)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "\n",
    "        for i in indexes:\n",
    "\n",
    "            CF_r[int(i/num_classes),:,c] = CF[:,i+c].T\n",
    "\n",
    "    return(CF_r) \n",
    "\n",
    "###########\n",
    "    \n",
    "CF_r = reshape_confidence_matrix(CF1)  \n",
    "\n",
    "#print(CF_r)\n",
    "#print(CF_r.shape)\n",
    "predictions_step1 = Gompertz(CF_r)\n",
    "\n",
    "print(predictions_step1)\n",
    "\n",
    "#############\n",
    "\n",
    "CF_r_fortworth = reshape_confidence_matrix(CF1_F)\n",
    "\n",
    "predictions_step1_fortworth = Gompertz(CF_r_fortworth)\n",
    "\n",
    "print(predictions_step1_fortworth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make GSV Labels Consistent to Step 1 Result (Orthophoto and LiDAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 30)\n"
     ]
    }
   ],
   "source": [
    "# 0 (aprtment) >> 4 (residential)\n",
    "# 1 (church)  >> 1 (institutional)\n",
    "# 2 (house)   >> 4 (residential)\n",
    "# 3 (industrial) >> 0 (industrial)\n",
    "# 4 (mixed r/c)  >> 5 (retail)\n",
    "# 5 (office building)  >> 2 (office building)\n",
    "# 6 (retail)  >>  5 (retail)\n",
    "\n",
    "def make_gsv_labels_consistent_to_ortho_lidar(prob_array_gsv):\n",
    "    \n",
    "    NUM_FOLDS = 5\n",
    "    \n",
    "    num_classes_gsv = 7\n",
    "    \n",
    "    num_cols = np.shape(prob_array_gsv)[1]\n",
    "    \n",
    "    prob_array_gsv_c = np.copy(prob_array_gsv)\n",
    "    \n",
    "    for i in range(NUM_FOLDS):\n",
    "\n",
    "        apt = np.copy(prob_array_gsv[:,0+i*num_classes_gsv])\n",
    "\n",
    "        house = np.copy(prob_array_gsv[:,2+i*num_classes_gsv])\n",
    "\n",
    "        industrial = np.copy(prob_array_gsv[:,3+i*num_classes_gsv])\n",
    "\n",
    "        mixed = np.copy(prob_array_gsv[:,4+i*num_classes_gsv])\n",
    "\n",
    "        office_b = np.copy(prob_array_gsv[:,5+i*num_classes_gsv])\n",
    "\n",
    "        retail = np.copy(prob_array_gsv[:,6+i*num_classes_gsv])\n",
    "\n",
    "        prob_array_gsv_c[:,0+i*num_classes_gsv] = industrial\n",
    "\n",
    "        prob_array_gsv_c[:,2+i*num_classes_gsv] = office_b\n",
    "\n",
    "        prob_array_gsv_c[:,3+i*num_classes_gsv] = np.zeros((prob_array_gsv.shape[0],))  # class \"other\" has zero probability in gsv\n",
    "\n",
    "        #take the maximum probability between apartment and house\n",
    "\n",
    "        prob_array_gsv_c[:,4+i*num_classes_gsv] = np.max(np.concatenate((np.expand_dims(apt,axis=1),np.expand_dims(house,axis=1)),axis=1))\n",
    "\n",
    "        #take the maximum probability between mixed r/c and retail\n",
    "\n",
    "        prob_array_gsv_c[:,5+i*num_classes_gsv] = np.max(np.concatenate((np.expand_dims(mixed,axis=1), np.expand_dims(retail,axis=1)),axis=1))\n",
    "        \n",
    "    # remove redundant columns (you now have 6 classes) \n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for j in np.arange(num_classes_gsv-1, num_cols, num_classes_gsv):\n",
    "\n",
    "        prob_array_gsv_c = np.delete(prob_array_gsv_c,[j-counter], axis=1)\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    #normalization\n",
    "    \n",
    "    prob_array_gsv_c_n = np.copy(prob_array_gsv_c)\n",
    "    \n",
    "    for k in range(prob_array_gsv_c.shape[0]):\n",
    "        \n",
    "        prob_array_gsv_c_n[k,:] = (prob_array_gsv_c[k,:]-np.min(prob_array_gsv_c[k,:]))/(np.max(prob_array_gsv_c[k,:])-np.min(prob_array_gsv_c[k,:]))\n",
    "    \n",
    "    return(prob_array_gsv_c_n) \n",
    "\n",
    "###################\n",
    "        \n",
    "vancouver_prob_array_gsv_c_n = make_gsv_labels_consistent_to_ortho_lidar(vancouver_prob_array_gsv)   \n",
    "\n",
    "#print(vancouver_prob_array_gsv_c_n.shape)\n",
    "\n",
    "####################\n",
    "\n",
    "fortworth_prob_array_gsv_c_n = make_gsv_labels_consistent_to_ortho_lidar(fortworth_prob_array_gsv)\n",
    "\n",
    "print(fortworth_prob_array_gsv_c_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 4 5 5 5 4 4 4 5 4 4 5 4 4 4 5 4 4 4 5 4 5 4 5 5 4 4 5 4 4 5 5 5 5 4 4\n",
      " 5 4 4 5 4 5 5 5 4 4 5 4 4 5 4 4 4 5 4 4 4 4 4 4 4 4 4 4 4 4 4 5 4 4 5 4 5\n",
      " 4 4 4 4 4 4 5 4 4 4 5 4 4 4 4 4 4 5 4 5 4 4 5 4 5 4 4 4 4 5 4 4 4 4 4 4 5\n",
      " 5 4 4 5 4 4 5 4 4 5 5 5 4 4 4 4 4 5 4 5 4 4 4 4 4 5 4 4 4 5 4 4 4 4 5 4 5\n",
      " 5 5 4 5 4 4 5 5 5 4 4 5 4 4 5 5 4 5 5 5 5 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[5 5 5 4 5 2 5 5 5 5 4 4 5 4 5 4 5 4 5 5 4 5 5 5 5 5 5 5 5 5 5 5 4 2 5 5 5\n",
      " 5 5 5 4 5 3 4 4 5 5 5 4 2 5 5 3 5 5 5 5 5 4 4 2 5 2 5 5 4 5 5 4 5 5 5 5 5\n",
      " 4 5 5 5 5 5 5 5 5 5 5 5 4 5 4 4 4 5 4 5 5 4 3 5 5 5 5 5 5 5 4 5 5 5 5 5 5\n",
      " 5 5 5 4 4 5 5 5 5 5 5 5 5 5 5 4 4 4 4 5 5 5 4 5 4 4 4 4 5 5 4 4 5 5 4 5 5\n",
      " 4 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5 4 5 5 4 5 5 4 5 4 5 4 5 4 4 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 4 5 5 5 4 4 5 4 4 4 5 5 5 5 5 4 4 5 4 5 5 4 5 4 5 5 5 5 4 4 5\n",
      " 5 4 4 4 5 4 4 5 4 5 5 4 5 5 4 5 5 5 5 5 4 5 5 5 5 5 2 5 5 5 4 5 5 5 5 5 5\n",
      " 5 5 5 5 4 2 5 5 5 5 5 5 5 5 5 5 4 5 5 4 5 5 5 5 4 4 5 5 5 5 5 5 5 5 4 5 5\n",
      " 5 5 5 5 5 4 5 5 5 2 5 4 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 4 5 4 5\n",
      " 5 4 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2\n",
      " 4 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 4 4 4 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "\n",
    "CF2 = np.concatenate((vancouver_prob_array_ortho_lidar, vancouver_prob_array_gsv_c_n), axis=1)\n",
    "\n",
    "#print(CF2.shape)\n",
    "\n",
    "CF2_r = reshape_confidence_matrix(CF2)\n",
    "\n",
    "#print(CF2_r)\n",
    "\n",
    "#print(CF2_r.shape)\n",
    "\n",
    "predictions = Gompertz(CF2_r)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "##############\n",
    "\n",
    "CF2_fortworth = np.concatenate((fortworth_prob_array_ortho_lidar, fortworth_prob_array_gsv_c_n), axis=1)\n",
    "\n",
    "CF2_fortworth_r = reshape_confidence_matrix(CF2_fortworth)\n",
    "\n",
    "predictions_f = Gompertz(CF2_fortworth_r)\n",
    "\n",
    "print(predictions_f)\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Predictions to the Original CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.concat([df, pd.DataFrame(predictions, columns = ['Fuzzy_Fusion_Predictions'])], axis =1)\n",
    "\n",
    "df1.to_csv('D:/Nafiseh/building_type/vancouver_prob_test_2_new.csv')\n",
    "\n",
    "#########################################\n",
    "\n",
    "df2 = pd.concat([df_fortworth, pd.DataFrame(predictions_f, columns = ['Fuzzy_Fusion_Predictions'])], axis =1)\n",
    "\n",
    "df2.to_csv('D:/Nafiseh/building_type/fortworth_prob_test_2_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize and Save Fusion Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function; Adapted to Fortworth Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_figure(fusion_array, path):\n",
    "    \n",
    "    #orange_patch = mpatches.Patch(color = 'orange', label = 'industrial')\n",
    "    \n",
    "    #cyan_patch = mpatches.Patch(color = 'cyan', label='institutional')\n",
    "    \n",
    "    darkred_patch = mpatches.Patch(color = 'darkred', label = 'office building')\n",
    "    \n",
    "    red_patch = mpatches.Patch(color = 'red', label = 'other')\n",
    "    \n",
    "    blue_patch = mpatches.Patch(color = 'blue', label='residential')\n",
    "\n",
    "    magenta_patch = mpatches.Patch(color = 'magenta', label = 'retail')\n",
    "\n",
    "    #green_patch = mpatches.Patch(color = 'green', label = 'house')\n",
    "\n",
    "    yellow_patch = mpatches.Patch(color = 'yellow', label = 'background')\n",
    "\n",
    "    colors = ['darkred','red','blue','magenta', 'yellow']\n",
    "    \n",
    "        \n",
    "    extent_f = [-97.340242, -97.326509, 32.746281, 32.757833]  # fortworth\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    ax.tick_params(labeltop = True, labelright = True)\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.rcParams['font.size'] = 40\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [40, 20]\n",
    "    \n",
    "    u = np.unique(fusion_array)\n",
    "\n",
    "    norm = BoundaryNorm(list(np.arange(np.min(u)-1,u[-2]+1,17))+list(np.arange(u[-2]+1,np.max(u)+2,170)), len(u))\n",
    "\n",
    "    cmap_listed = ListedColormap(colors)\n",
    "\n",
    "    plt.imshow(fusion_array, cmap = cmap_listed, norm = norm, extent = extent_f)\n",
    "\n",
    "    plt.legend(handles = [darkred_patch, red_patch, blue_patch, magenta_patch, yellow_patch], loc = 'lower center',bbox_to_anchor = (-0.1,-0.15))\n",
    "\n",
    "    plt.xlabel('Longitude (deg)', font = 'Times New Roman', fontsize = 50, fontweight = 'bold')\n",
    "    \n",
    "    plt.ylabel('Latitude (deg)', font = 'Times New Roman', fontsize = 50, fontweight = 'bold')\n",
    "    \n",
    "    plt.xticks(np.arange(-97.340242, -97.326509, 0.005))\n",
    "    \n",
    "    plt.yticks(np.arange(32.746281, 32.757833, 0.005))\n",
    "    \n",
    "    plt.axis('on')\n",
    "\n",
    "    plt.savefig(path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "################################\n",
    "\n",
    "# 34 >> office building, 51 >> other, 68 >> residential, 85 >> retail, 255 >> background\n",
    "\n",
    "################################\n",
    "\n",
    "gompertz_fortworth = np.array(Image.open('D:/Nafiseh/building_type/fortworth_gompertz_fused.tif'))\n",
    "\n",
    "#print(np.unique(gompertz_fortworth))\n",
    "\n",
    "#print(np.unique(gompertz_fortworth), gompertz_fortworth.shape)\n",
    "\n",
    "#plt.imshow(gompertz_fortworth)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "visualize_and_save_figure(gompertz_fortworth,'D:/Nafiseh/building_type/fortworth_gompertz_fused_figure_2.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function; Adapted to Vancouver Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_figure_2(fusion_array, path):\n",
    "    \n",
    "    #orange_patch = mpatches.Patch(color = 'orange', label = 'industrial')\n",
    "    \n",
    "    #cyan_patch = mpatches.Patch(color = 'cyan', label='institutional')\n",
    "    \n",
    "    #darkred_patch = mpatches.Patch(color = 'darkred', label = 'office building')\n",
    "    \n",
    "    #red_patch = mpatches.Patch(color = 'red', label = 'other')\n",
    "    \n",
    "    blue_patch = mpatches.Patch(color = 'blue', label='residential')\n",
    "\n",
    "    magenta_patch = mpatches.Patch(color = 'magenta', label = 'retail')\n",
    "\n",
    "    #green_patch = mpatches.Patch(color = 'green', label = 'house')\n",
    "\n",
    "    yellow_patch = mpatches.Patch(color = 'yellow', label = 'background')\n",
    "\n",
    "    colors = ['blue','magenta', 'yellow']\n",
    "    \n",
    "    extent = [-123.136140, -123.129303, 49.280349, 49.284829]  # vancouver\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    \n",
    "    ax.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "    \n",
    "    ax.tick_params(labeltop = True, labelright = True)\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    plt.rcParams['font.size'] = 40\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [40,20]\n",
    "    \n",
    "    u = np.unique(fusion_array)\n",
    "\n",
    "    norm = BoundaryNorm(list(np.arange(np.min(u)-1,u[-2]+1,17))+list(np.arange(u[-2]+1,np.max(u)+2,170)), len(u))\n",
    "\n",
    "    cmap_listed = ListedColormap(colors)\n",
    "\n",
    "    plt.imshow(fusion_array, cmap = cmap_listed, norm = norm, extent = extent)\n",
    "\n",
    "    plt.legend(handles = [blue_patch, magenta_patch, yellow_patch], loc = 'lower center',bbox_to_anchor = (-0.01,-0.15))\n",
    "\n",
    "    plt.xlabel('Longitude (deg)', font = 'Times New Roman', fontsize = 50, fontweight = 'bold')\n",
    "    \n",
    "    plt.ylabel('Latitude (deg)', font = 'Times New Roman', fontsize =50, fontweight = 'bold')\n",
    "    \n",
    "    plt.xticks(np.arange(-123.136140, -123.129303, 0.003))\n",
    "    \n",
    "    plt.yticks(np.arange(49.280349, 49.284829, 0.002))\n",
    "    \n",
    "    plt.axis('on')\n",
    "\n",
    "    plt.savefig(path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import Resampling\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "gompertz_vancouver = Image.open('D:/Nafiseh/building_type/vancouver_gompertz_fuse.tif').resize((2560,2560), resample = Resampling.NEAREST)\n",
    "\n",
    "visualize_and_save_figure_2(gompertz_vancouver, 'D:/Nafiseh/building_type/vancouver_gompertz_fused_figure_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Ground Truth File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel-Based Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pil_fusion_map_labels_to_original(fusion_array):\n",
    "    \n",
    "    fusion_array [fusion_array == 34] = 2\n",
    "    \n",
    "    fusion_array [fusion_array == 51] = 3\n",
    "    \n",
    "    fusion_array [fusion_array == 68] = 4\n",
    "    \n",
    "    fusion_array [fusion_array == 85] = 5\n",
    "    \n",
    "    fusion_array [fusion_array == 255] = 6\n",
    "    \n",
    "    return(fusion_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     industrial       0.00      0.00      0.00     43668\n",
      "  institutional       0.00      0.00      0.00     15902\n",
      "office building       0.00      0.00      0.00    180637\n",
      "          other       0.00      0.00      0.00    115192\n",
      "    residential       0.45      0.41      0.43   1214447\n",
      "         retail       0.16      0.42      0.24    382736\n",
      "     background       0.87      0.85      0.86   4601018\n",
      "\n",
      "       accuracy                           0.70   6553600\n",
      "      macro avg       0.21      0.24      0.22   6553600\n",
      "   weighted avg       0.70      0.70      0.70   6553600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     industrial       0.00      0.00      0.00    444049\n",
      "  institutional       0.00      0.00      0.00    166926\n",
      "office building       0.52      0.03      0.06   4421130\n",
      "          other       0.80      0.14      0.24    315595\n",
      "    residential       0.07      0.31      0.12    495108\n",
      "         retail       0.03      0.49      0.05    214216\n",
      "     background       0.89      0.87      0.88  20157376\n",
      "\n",
      "       accuracy                           0.68  26214400\n",
      "      macro avg       0.33      0.26      0.19  26214400\n",
      "   weighted avg       0.78      0.68      0.69  26214400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from PIL.Image import Resampling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "############################## Labels in Ground Truth Map ##############################\n",
    "\n",
    "# 0 >> background, 20 >> apartment, 38 >> office building, 76 >> garage, 90 >> roof, \n",
    "# 105 >> retail, 142 >> industrial, 150 >> house, 179 >> institutional\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "############################### Labels in Fusion Map #####################################\n",
    "\n",
    "# 34 >> office building, 51 >> other, 68 >> residential, 85 >> retail, 255 >> background\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "################################## Vancouver #############################################\n",
    "\n",
    "class_names = ['industrial','institutional','office building','other','residential','retail','background']\n",
    "\n",
    "gt_vancouver = make_gt_labels_consistent_to_fusion_map(np.array(Image.open(r'F:\\Backup_Nafiseh_Hard_Drives\\BIC_GSV.tar\\BIC_GSV\\vancouver_test_region\\vancouver_groundtruth_gray.png')))\n",
    "\n",
    "gompertz_vancouver = convert_pil_fusion_map_labels_to_original(np.array(Image.open('D:/Nafiseh/building_type/vancouver_gompertz_fuse.tif').resize((2560,2560), resample = Resampling.NEAREST)))\n",
    "\n",
    "#print(np.unique(gt_vancouver), np.unique(gompertz_vancouver))\n",
    "\n",
    "#print(gt_vancouver.shape, gompertz_vancouver.shape)\n",
    "\n",
    "print(classification_report(np.ravel(gt_vancouver), np.ravel(gompertz_vancouver), target_names = class_names))\n",
    "\n",
    "################################# Fortworth ##################################################\n",
    "\n",
    "class_names = ['industrial','institutional','office building','other','residential','retail','background']\n",
    "\n",
    "gt_fortworth = make_gt_labels_consistent_to_fusion_map(np.array(Image.open(r'F:\\Backup_Nafiseh_Hard_Drives\\BIC_GSV.tar\\BIC_GSV\\fortworth_test_region\\fortworth_groundtruth_gray.png')))\n",
    "\n",
    "gompertz_fortworth = convert_pil_fusion_map_labels_to_original(np.array(Image.open('D:/Nafiseh/building_type/fortworth_gompertz_fused.tif').resize((5120,5120), resample = Resampling.NEAREST)))\n",
    "\n",
    "#print(np.unique(gt_fortworth), np.unique(gompertz_fortworth))\n",
    "\n",
    "#print(gt_fortworth.shape, gompertz_fortworth.shape)\n",
    "\n",
    "print(classification_report(np.ravel(gt_fortworth), np.ravel(gompertz_fortworth), target_names = class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object-Based Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "#from osgeo import gdal\n",
    "\n",
    "#fortworth_gt_gdal = gdal.Open(r'F:\\Backup_Nafiseh_Hard_Drives\\BIC_GSV.tar\\BIC_GSV\\fortworth_test_region\\fortworth_groundtruth_gray.png')\n",
    "\n",
    "#fortworth_gt = fortworth_gt_gdal.ReadAsArray()\n",
    "\n",
    "#print(np.unique(fortworth_gt))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_pred_fortworth = pd.read_csv('D:/Nafiseh/building_type/fortworth_prob_test_2_new.csv')\n",
    "\n",
    "df_gt_fortworth = pd.read_csv('D:/Nafiseh/building_type/fortworth_gt_zst.csv')\n",
    "\n",
    "df_m_f = pd.merge(df_pred_fortworth, df_gt_fortworth, on= 'CFWLAND_ID')\n",
    "\n",
    "gt_f = np.array(df_m_f.GT_2)\n",
    "\n",
    "predictions_f_ = np.array(df_m_f.Fuzzy_Fusion_Predictions)\n",
    "\n",
    "#df_m_f\n",
    "##################################\n",
    "\n",
    "df_pred_vancouver = pd.read_csv('D:/Nafiseh/building_type/vancouver_prob_test_2_new.csv')\n",
    "\n",
    "df_gt_vancouver = pd.read_csv('D:/Nafiseh/building_type/vancouver_gt_zst_4.csv')\n",
    "\n",
    "df_m_v = pd.merge(df_pred_vancouver, df_gt_vancouver, on='obj_id_lng')\n",
    "\n",
    "gt_v = np.array(df_m_v.GT_2)\n",
    "\n",
    "predictions_v_ = np.array(df_m_v.Fuzzy_Fusion_Predictions)\n",
    "\n",
    "#df_m_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ground Truth Labels Consistent to Fusion Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "(401,)\n",
      "[2 3 4 5 6]\n",
      "(184,)\n"
     ]
    }
   ],
   "source": [
    "def make_gt_labels_consistent_to_fusion_map(gt):\n",
    "\n",
    "    # labels in fusion map:\n",
    "    \n",
    "    # 0 >> industrial, 1 >> institutional, 2 >> office building, 3 >> other, 4 >> residential, 5 >> retail\n",
    "\n",
    "    gt[gt == 0] = 6\n",
    "\n",
    "    gt[(gt == 29) | (gt == 150)] = 4\n",
    "\n",
    "    gt[gt == 38] = 2\n",
    "\n",
    "    gt[gt == 142] = 0\n",
    "\n",
    "    gt[gt == 105] = 5\n",
    "\n",
    "    gt[gt == 179] = 1\n",
    "\n",
    "    gt[(gt == 76) | (gt == 90)] = 3\n",
    "    \n",
    "    return(gt)\n",
    "\n",
    "\n",
    "#############################3\n",
    "    \n",
    "fortworth_gt_new_label = np.array(make_gt_labels_consistent_to_fusion_map(gt_f))\n",
    "\n",
    "print(np.unique(fortworth_gt_new_label))\n",
    "\n",
    "print(fortworth_gt_new_label.shape)\n",
    "\n",
    "###########################\n",
    "\n",
    "vancouver_gt_new_label = np.array(make_gt_labels_consistent_to_fusion_map(gt_v))\n",
    "\n",
    "print(np.unique(vancouver_gt_new_label))\n",
    "\n",
    "print(vancouver_gt_new_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  institutional       0.00      0.00      0.00        14\n",
      "office building       0.33      0.03      0.06        96\n",
      "          other       1.00      0.03      0.05       108\n",
      "    residential       0.08      0.11      0.09        75\n",
      "         retial       0.05      0.43      0.09        35\n",
      "     background       0.00      0.00      0.00        73\n",
      "\n",
      "       accuracy                           0.07       401\n",
      "      macro avg       0.24      0.10      0.05       401\n",
      "   weighted avg       0.37      0.07      0.05       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "class_names = ['institutional','office building','other','residential','retial','background']\n",
    "\n",
    "print(classification_report(fortworth_gt_new_label, predictions_f_, target_names = class_names))\n",
    "\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(fortworth_gt_new_label, predictions_f_), display_labels = class_names)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "office building       0.00      0.00      0.00         2\n",
      "          other       0.00      0.00      0.00        21\n",
      "    residential       0.39      0.63      0.48        70\n",
      "         retail       0.35      0.35      0.35        71\n",
      "     background       0.00      0.00      0.00        20\n",
      "\n",
      "       accuracy                           0.38       184\n",
      "      macro avg       0.15      0.20      0.17       184\n",
      "   weighted avg       0.28      0.38      0.32       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_names_2 = ['office building','other','residential','retail','background']\n",
    "\n",
    "print(classification_report(vancouver_gt_new_label, predictions_v_, target_names = class_names_2))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(vancouver_gt_new_label, predictions_v_), display_labels = class_names_2)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortworth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_same_as_gt(array):\n",
    "    \n",
    "    array [array == 4] = 29\n",
    "    \n",
    "    array [array == 5] = 105\n",
    "    \n",
    "    array[array == 6] = 0\n",
    "\n",
    "    array[array == 4] = 29\n",
    "\n",
    "    array[array == 2] = 38\n",
    "\n",
    "    array[array == 3] = 90\n",
    "\n",
    "    array[array == 5] = 105\n",
    "\n",
    "    array[array == 0] = 142\n",
    "\n",
    "    array[array == 4] = 150\n",
    "\n",
    "    array[array == 3] = 179\n",
    "    \n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "df = pd.read_csv('D:/Nafiseh/building_type/fortworth_fuzzy_spj_new_table.csv')\n",
    "\n",
    "df_fuzzy = pd.read_csv('D:/Nafiseh/building_type/fortworth_prob_test_2_new.csv')\n",
    "\n",
    "class_names = ['background','apartment','office building','roof','garage','retail','industrial','house','church']\n",
    "\n",
    "df_final = pd.merge(df,df_fuzzy, on = 'ADDRESS')\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(np.array(df_final['gridcode']), make_labels_same_as_gt(np.array(df_final['Fuzzy_Fusion_Predictions']))), display_labels = class_names)\n",
    "\n",
    "disp.plot()\n",
    "                                          \n",
    "#_,ax=plt.subplots(figsize=(25,15))\n",
    "\n",
    "#sns.set (font_scale = 2)                                          \n",
    "\n",
    "#sns.heatmap(confusion_matrix/np.sum(confusion_matrix,axis=1)[:,None], annot=True, fmt='.2%', cmap='Blues',ax=ax)\n",
    "\n",
    "#sns.heatmap(confusion_matrix, annot=True, fmt='.2%', cmap='Blues',ax=ax)\n",
    "\n",
    "#ax.set_xlabel('Predicted labels',fontweight='bold',fontsize = 20)\n",
    "#ax.set_ylabel('True labels',fontweight='bold',fontsize = 20)\n",
    "#ax.set_title('Confusion Matrix',fontweight='bold',fontsize = 26) \n",
    "\n",
    "    \n",
    "#ax.xaxis.set_ticklabels(['office building','other','residential','retail'], fontsize = 18)\n",
    "                           \n",
    "\n",
    "#ax.yaxis.set_ticklabels(['office building','other','residential','retail'], fontsize = 18)\n",
    "                        \n",
    "\n",
    "#plt.savefig('D:/Nafiseh/building_type/Building_Type_Manuscript/confusion_matrix_vancouver_fuzzy.tif')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vancouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_same_as_gt(array):\n",
    "    \n",
    "    array [array == 4] = 29\n",
    "    \n",
    "    array [array == 5] = 105\n",
    "    \n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "df = pd.read_csv('D:/Nafiseh/building_type/vancouver_prob_test_spj_new.csv')\n",
    "\n",
    "class_names = ['background','apartment','office building','garage','retail','industrial','house','church']\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(np.array(df['gridcode']), make_labels_same_as_gt(np.array(df['Fuzzy_Fusion']))), display_labels = class_names)\n",
    "\n",
    "disp.plot()\n",
    "                                          \n",
    "#_,ax=plt.subplots(figsize=(25,15))\n",
    "\n",
    "#sns.set (font_scale = 2)                                          \n",
    "\n",
    "#sns.heatmap(confusion_matrix/np.sum(confusion_matrix,axis=1)[:,None], annot=True, fmt='.2%', cmap='Blues',ax=ax)\n",
    "\n",
    "#sns.heatmap(confusion_matrix, annot=True, fmt='.2%', cmap='Blues',ax=ax)\n",
    "\n",
    "#ax.set_xlabel('Predicted labels',fontweight='bold',fontsize = 20)\n",
    "#ax.set_ylabel('True labels',fontweight='bold',fontsize = 20)\n",
    "#ax.set_title('Confusion Matrix',fontweight='bold',fontsize = 26) \n",
    "\n",
    "    \n",
    "#ax.xaxis.set_ticklabels(['office building','other','residential','retail'], fontsize = 18)\n",
    "                           \n",
    "\n",
    "#ax.yaxis.set_ticklabels(['office building','other','residential','retail'], fontsize = 18)\n",
    "                        \n",
    "\n",
    "#plt.savefig('D:/Nafiseh/building_type/Building_Type_Manuscript/confusion_matrix_vancouver_fuzzy.tif')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
